<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Mengkun She</title>

  <meta name="author" content="Mengkun She">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Mengkun She | 佘梦坤
                  </p>
                  <p>Hi! I'm a Ph.D. student at the <a href="https://www.inf.uni-kiel.de/de"> Institute of Computer
                      Science</a>, <a href="https://www.uni-kiel.de/de/">Christian-Albrechts-Universität zu Kiel</a> in
                    Germany. Here, I'm working in the <a
                      href="https://www.marine.informatik.uni-kiel.de/en/about">Marine Data Science</a> group advised by
                    Prof. Dr. Kevin Köser.
                  </p>
                  <p>Before moving to Kiel University, I was a research scientist in the <a
                      href="https://www.geomar.de/en/omv">Oceanic Machine Vision</a> group at <a
                      href="https://www.geomar.de">GEOMAR Helmholtz-Zentrum für Ozeanforschung Kiel</a></p>
                  <p style="text-align:center">
                    <a href="mailto:mengkun.she@gmail.com">Email</a> &nbsp;/&nbsp;
                    <a href="data/CV_update_202501.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=KmPypAEAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                    <a href="https://github.com/Serenitysmk">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/mshe.jpg"><img
                      style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo"
                      src="images/mshe.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="60%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="50%" valign="middle">
                <a href="https://www.marine.informatik.uni-kiel.de/en/about"><img src="media/cau_logo.png"
                    width="120"></a>
              </td>
              <td width="50%" valign="middle">
                <a href="https://www.geomar.de/en/omv"><img src="media/geomar_white_logo.jpg" width="120"></a>
              </td>
            </tr>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    At <a href="https://www.marine.informatik.uni-kiel.de/en/about">MDS</a> group, we focus on
                    Artificial Intelligence and Perception for the Marine Sciences and Environments, in particular at
                    the interface of Computer Vision, Computer Graphics, Robotics and Machine Learning. We therefore
                    need to deal with challenging but very interesting real-world images acquired by deep-sea robots.
                    <span class="highlight">Highlights</span> are the major works.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!--AUV Mapping book chapter-->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/auv_mapping_book.png' alt="rsfm" width="160">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://link.springer.com/chapter/10.1007/978-3-031-59531-8_3">
                    <span class="papertitle">Autonomous Visual 3D Mapping of the Ocean Floor by Underwater Robots Equipped with a Single Photo Camera</span>
                  </a>
                  <br>
                  <a
                    href="https://www.marine.informatik.uni-kiel.de/en/team">Kevin Köser</a>, <strong>Mengkun
                    She</strong>, Nikolaj Diller, Sylvia Reissmann, Tim Weiß, etc ...
                  <br>
                  <em>[Springer Book Chapter] Scanning Technologies for Autonomous Systems</em>
                </td>
              </tr>

              <!--Refractive COLMAP-->
              <tr bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/standard_colmap.gif' alt="rsfm" width="160">
                  <img src='images/refrac_sfm.gif' alt="rsfm" width="160">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2403.08640">
                    <span class="papertitle">Refractive COLMAP: Refractive Structure-from-Motion Revisited</span>
                  </a>
                  <br>
                  <strong>Mengkun
                    She</strong>, Felix Seegräber, <a href="https://www.geomar.de/dnakath">David Nakath</a>, <a
                    href="https://www.marine.informatik.uni-kiel.de/en/team">Kevin Köser</a>
                  <br>
                  <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (<strong>IROS</strong>)</em>,
                  2024 (<strong style="color:red">Oral Presentation</strong>)
                  <br>
                  <a href="https://arxiv.org/abs/2403.08640">Preprint</a> / <a
                    href="https://cau-git.rz.uni-kiel.de/inf-ag-koeser/colmap_underwater">Code</a>
                  <p>Underwater cameras suffer from geometric distortion induced by refraction of light rays at the
                    water-glass-air interfaces. There has been works going on to analyze and calibrate such systems.
                    However, we ask the question: what are you going to do with the calibrated refractive cameras? Can
                    you use it in structure-from-motion? We therefore integrate the refractive geomtry within the COLMAP
                    framework and release it as open-source.</p>
                </td>
              </tr>

              <!--JFR AUV mapping-->
              <tr bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <!-- <img src='images/auv_mapping.png' alt="auv_mapping" width="160"> -->
                  <div class="one" id='auv_mapping'><video width=100% height=100% muted autoplay loop>
                    <source src="images/auv_mapping.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/rob.22390">
                    <span class="papertitle">Semihierarchical Reconstruction and Weak-area Revisiting for Robotic Visual
                      Seafloor Mapping</span>
                  </a>
                  <br>
                  <strong>Mengkun
                    She</strong>, <a href="https://scholar.google.com/citations?user=3KQHqaIAAAAJ&hl=en">Yifan Song</a>,
                  <a href="https://www.geomar.de/dnakath">David Nakath</a>, <a
                    href="https://www.marine.informatik.uni-kiel.de/en/team">Kevin Köser</a>
                  <br>
                  <em>Journal of Field Robotics</em>
                  <br>
                  <p>A semi-hierarchical approach which combines the good parts of incremental and global
                    structure-from-motion for large-scale AUV-based monocular camera seafloor reconstruction. Weak-area
                    revisiting helps to mitigate
                    inconsistencies in the reconstructed camera poses and map.</p>
                </td>
              </tr>

              <!--UWSLAM evaluation-->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/michela_uwslam_eval.png' alt="uwslam_eval" width="160">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://isprs-annals.copernicus.org/articles/X-1-W1-2023/1113/2023/">
                    <span class="papertitle">Investigation of the Challenges of Underwater-Visual-Monocular-SLAM</span>
                  </a>
                  <br>
                  <a href="https://www.researchgate.net/profile/Michele-Grimaldi-7">Michele Grimaldi</a>, <a
                    href="https://www.geomar.de/dnakath">David Nakath</a>, <strong>Mengkun
                    She</strong>, <a href="https://www.marine.informatik.uni-kiel.de/en/team">Kevin Köser</a>
                  <br>
                  <em>ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences</em>
                  <br>
                </td>
              </tr>

              <!--3DV Visual tomography-->
              <tr bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one" id='visual_tomo'><video width=100% height=100% muted autoplay loop>
                      <source src="images/dp_dr_lo_validation_hi_res.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://ieeexplore.ieee.org/abstract/document/10550533">
                    <span class="papertitle">Visual Tomography: Physically Faithful Volumetric Models of Partially
                      Translucent Objects</span>
                  </a>
                  <br>
                  <a href="https://www.geomar.de/dnakath">David Nakath</a>, <a
                    href="https://www.geomar.de/xweng">Xiangyu Weng</a>, <strong>Mengkun She</strong>, <a href="https://www.marine.informatik.uni-kiel.de/en/team">Kevin
                    Köser</a>
                  <br>
                  <br>
                  <em>International Conference on 3D Vision (<strong>3DV</strong>)</em>, 2024
                  <br>
                  <a href="https://arxiv.org/abs/2312.13494">Preprint</a> / <a
                    href="https://cloud.rz.uni-kiel.de/index.php/s/8jWqn8xAkpwGmTH">Poster</a> / <a
                    href="https://cloud.rz.uni-kiel.de/index.php/s/Bi5bCogXrH3p43T">Supplementary Material / Data</a>

                  <p>How to establish 3D models of partially translucent organisms? We adapt Differentiable Raytracing
                    to real data to: 1. capture Tomography-like internal structure; 2. establish relightable models; 3.
                    immerse models in other media; 4. exhibit high novel-view stability</p>
                </td>
              </tr>

              <!--Yifan's look up table-->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/lut3d.png' alt="lut3d" width="160">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://www.sciencedirect.com/science/article/pii/S0924271624000479">
                    <span class="papertitle">Advanced Underwater Image Restoration in Complex Illumination
                      conditions</span>
                  </a>
                  <br>
                  <a href="https://scholar.google.com/citations?user=3KQHqaIAAAAJ&hl=en">Yifan Song</a>, <strong>Mengkun
                    She</strong>, <a href="https://www.marine.informatik.uni-kiel.de/en/team">Kevin Köser</a>
                  <br>
                  <em>ISPRS Journal of Photogrammetry and Remote Sensing</em>
                  <br>
                  <p>A 3D look-up-table to represent the complex illumination field for underwater image restoration
                    tasks.</p>
                </td>
              </tr>

              <!--BubbleBox-->
              <tr bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one" id='bubblebox'><video width=100% height=100% muted autoplay loop>
                    <source src="images/bubblebox_small.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://www.sciencedirect.com/science/article/pii/S092427162200171X">
                    <span class="papertitle">Marine Bubble Flow Quantification Using Wide-baseline Stereo
                      Photogrammetry</span>
                  </a>
                  <br>
                  <strong>Mengkun She</strong>, Tim Weiß, <a
                    href="https://scholar.google.com/citations?user=3KQHqaIAAAAJ&hl=en">Yifan Song</a>, Peter Urban, <a
                    href="https://www.geomar.de/deepsea-monitoring">Jens Greinert</a>, <a
                    href="https://www.marine.informatik.uni-kiel.de/en/team">Kevin Köser</a>
                  <br>
                  <br>
                  <em>ISPRS Journal of Photogrammetry and Remote Sensing</em>
                  <br>

                  <p>The BubbleBox project aims to develop a high-speed stereo camera system that can be deployed on the
                    seafloor of the deep ocean to measure and quantify the amount of gas released from the seafloor into
                    the water column. <a href="https://www.youtube.com/watch?v=8mAJoxXaKFo"> Checkout the livestream of
                      the BubbleBox deployment!</a></p>
                </td>
              </tr>

              <!--Survey image restoration methods-->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/yifan_survey.png' alt="yifan_survey" width="160">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://link.springer.com/article/10.1007/s41064-022-00206-y">
                    <span class="papertitle">Optical Imaging and Image Restoration Techniques for Deep Ocean Mapping: A
                      Comprehensive Survey</span>
                  </a>
                  <br>
                  <a href="https://scholar.google.com/citations?user=3KQHqaIAAAAJ&hl=en">Yifan Song</a>, <a
                    href="https://www.geomar.de/dnakath">David Nakath</a>, <strong>Mengkun She</strong>, <a
                    href="https://www.marine.informatik.uni-kiel.de/en/team">Kevin Köser</a>
                  <br>
                  <em>PFG - Journal of Photogrammetry, Remote Sensing and Geoinformation Science</em>
                  <br>

                  <p>We made a survey on different state-of-the-art underwater image restoration methods for deep-sea
                    optical imaging systems.
                  </p>
                </td>
              </tr>

              <!--Digital twin-->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/digital_twin.png' alt="digital_twin" width="160">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://link.springer.com/article/10.1007/s41064-021-00190-9">
                    <span class="papertitle">An Optical Digital Twin for Underwater Photogrammetry</span>
                  </a>
                  <br>
                  <a href="https://www.geomar.de/dnakath">David Nakath</a>, <strong>Mengkun She</strong>, <a
                    href="https://scholar.google.com/citations?user=3KQHqaIAAAAJ&hl=en">Yifan Song</a>, <a
                    href="https://www.marine.informatik.uni-kiel.de/en/team">Kevin Köser</a>
                  <br>
                  <em>PFG - Journal of Photogrammetry, Remote Sensing and Geoinformation Science</em>
                  <br>

                  <p>As the name suggests: a digital twin for underwater photogrammetry research. We particularly target
                    at refractive geometric verification.
                  </p>
                </td>
              </tr>

              <!--Refractive geometry for underwater domes-->
              <tr bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/refrac_dome.png' alt="refrac_dome" width="160" height="160">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://www.sciencedirect.com/science/article/pii/S092427162100304X">
                    <span class="papertitle">Refractive Geometry for Underwater Domes</span>
                  </a>
                  <br>
                  <strong>Mengkun She</strong>, <a href="https://www.geomar.de/dnakath">David Nakath</a>, <a
                    href="https://scholar.google.com/citations?user=3KQHqaIAAAAJ&hl=en">Yifan Song</a>, <a
                    href="https://www.marine.informatik.uni-kiel.de/en/team">Kevin Köser</a>
                  <br>
                  <em>ISPRS Journal of Photogrammetry and Remote Sensing</em>
                  <br>
                  <p>We look more into the refractive geometry properties of underwater dome-port cameras.</p>
                </td>
              </tr>

              <!--3DV Macal calibration-->
              <tr onmouseout="macal_stop()" onmouseover="macal_start()" bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='macal_image'><video width=100% height=100% muted autoplay loop>
                        <source src="images/macal_small.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='images/macal_image.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function macal_start() {
                      document.getElementById('macal_image').style.opacity = "1";
                    }

                    function macal_stop() {
                      document.getElementById('macal_image').style.opacity = "0";
                    }
                    macal_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://ieeexplore.ieee.org/abstract/document/9665843">
                    <span class="papertitle">Macal-Macro Lens Calibration and the Focus Stack Camera Model</span>
                  </a>
                  <br>
                  <a href="https://www.geomar.de/xweng">Xiangyu Weng*</a>, <strong>Mengkun She*</strong>, <a
                    href="https://www.geomar.de/dnakath">David Nakath</a>, <a
                    href="https://www.marine.informatik.uni-kiel.de/en/team">Kevin Köser</a>
                  <br>
                  <strong style="color:red">(*equal contribution)</strong>
                  <br>
                  <em>International Conference on 3D Vision (<strong>3DV</strong>)</em>, 2021 (<strong
                    style="color:red">Oral Presentation</strong>)
                  <br>
                  <a
                    href="https://www.geomar.de/fileadmin/content/forschen/fb2/mg/omv/macrocalibration.pdf">Preprint</a>

                  <p>We discover that the camera model of a focus stacked image is essentially an affine model. We then
                    propose a macro-lens calibration approach based on this insight for 3D reconstruction of very tiny
                    objects using such cameras. This technology is used in the <a
                      href="https://techoceans.eu">TechOceanS</a> project.</p>
                </td>
              </tr>

              <!--Light-water estimation paper-->
              <tr bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/lightunw.png' alt="lightunw" width="160" height="160">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a
                    href="https://openaccess.thecvf.com/content/ICCV2021W/OceanVision/html/Nakath_In-Situ_Joint_Light_and_Medium_Estimation_for_Underwater_Color_Restoration_ICCVW_2021_paper.html">
                    <span class="papertitle">In-Situ Joint Light and Medium Estimation for Underwater Color
                      Restoration</span>
                  </a>
                  <br>
                  <a href="https://www.geomar.de/dnakath">David Nakath</a>, <strong>Mengkun She</strong>, <a
                    href="https://scholar.google.com/citations?user=3KQHqaIAAAAJ&hl=en">Yifan Song</a>, <a
                    href="https://www.marine.informatik.uni-kiel.de/en/team">Kevin Köser</a>
                  <br>
                  <em>International Conference on Computer Vision Workshops (<strong>ICCV</strong>) Workshops</em>, 2021
                  <br>

                  <p>3D reconstruction using a camera with an active light source creates an uneven and color-distorted
                    texture. We use physically-based differentiable ray-tracing to firstly estimate the light source in
                    a calibration scenario, and then optimize a medium- and light- free texture in the subsequent SfM
                    step.
                  </p>
                </td>
              </tr>

              <!--Deep Sea Robotic Imaging Simulator-->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one" id='robsim_vid'><video width=100% height=100% muted autoplay loop>
                      <source src="images/yifan_deep_sea_simulation.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://link.springer.com/chapter/10.1007/978-3-030-68790-8_29">
                    <span class="papertitle">Deep Sea Robotic Imaging Simulator</span>
                  </a>
                  <br>
                  <a href="https://scholar.google.com/citations?user=3KQHqaIAAAAJ&hl=en">Yifan Song</a>, <a
                    href="https://www.geomar.de/dnakath">David Nakath</a>, <strong>Mengkun She</strong>, <a
                    href="https://felibol.github.io">Furkan Elibol</a>, <a
                    href="https://www.marine.informatik.uni-kiel.de/en/team">Kevin Köser</a>
                  <br>
                  <br>
                  <em>Pattern Recognition. ICPR International Workshops and Challenges</em>, 2021
                  <br>
                  <a href="https://arxiv.org/pdf/2006.15398">Preprint</a>

                  <p>A imaging simulator for deep-sea robots equipped with active light source.</p>
                </td>
              </tr>

              <!--Mingxing's paper-->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/mingxing.png' alt="mingxing" width="160" height="160">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://www.mdpi.com/2220-9964/9/6/362">
                    <span class="papertitle">An Illumination Insensitive Descriptor Combining the CSLBP Features for
                      Street View Images in Augmented Reality: Experimental Studies</span>
                  </a>
                  <br>
                  Zejun Xiang, <a href="https://ecivil.cqu.edu.cn/info/1016/1464.htm">Ronghua Yang</a>, Chang Deng,
                  MingXing Teng, <strong>Mengkun She</strong>, Degui Teng
                  <br>
                  <em>ISPRS International Journal of Geo-Information</em>
                  <br>
                  <p>Experimental study on illumination invariant features!</p>
                </td>
              </tr>

              <!--Dome calibration paper-->
              <tr onmouseout="domecalib_stop()" onmouseover="domecalib_start()" bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='tank_dome'><img src='images/tank_dome.gif' width="160" height="160"></div>
                    <img src='images/tank_dome.jpg' alt="tank_dome" width="160" height="160">
                  </div>
                  <script type="text/javascript">
                    function domecalib_start() {
                      document.getElementById('tank_dome').style.opacity = "1";
                    }

                    function domecalib_stop() {
                      document.getElementById('tank_dome').style.opacity = "0";
                    }
                    domecalib_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://link.springer.com/chapter/10.1007/978-3-030-33676-9_6">
                    <span class="papertitle">Adjustment and Calibration of Dome Port Camera Systems for Underwater
                      Vision</span>
                  </a>
                  <br>
                  <strong>Mengkun She</strong>, Yifan Song, Jochen Mohrmann, <a
                    href="https://www.marine.informatik.uni-kiel.de/en/team">Kevin Köser</a>
                  <br>
                  <em>41st DAGM German Conference on Pattern Recognition (<strong>GCPR</strong>)</em>, 2019 (<strong
                    style="color:red">Oral Presentation</strong>)
                  <br>
                  <a
                    href="https://www.geomar.de/fileadmin/personal/fb2/mg/kkoeser/domecalibration_preprint.pdf">Preprint</a>
                  <p>In this work, we develop an effective method to align a camera with an underwater spherical port
                    (dome-port) for underwater camera systems. This technique is essential for the accurate calibration
                    of our underwater cameras.</p>
                </td>
              </tr>

            </tbody>
          </table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <h2>Services</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>

              <tr>
                <!-- <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td> -->
                <td width="100%" valign="center">
                  <em>Teaching Assistant</em>: <a
                    href="https://moduldb.informatik.uni-kiel.de/show.cgi?mod=infMobRob%2D01a">Probabilistic Robotics,
                    Winter
                    2023, CAU</a> (now renamed to Mobile Robotics)
                  <br>
                </td>
              </tr>
              <tr>
                <td width="100%" valign="center">
                  <em>Reviewer</em>: <a
                    href="https://www.sciencedirect.com/journal/isprs-journal-of-photogrammetry-and-remote-sensing">ISPRS
                    Journal of Photogrammetry and Remote Sensing</a>; <a
                    href="https://link.springer.com/journal/41064">PFG Journal of Photogrammetry, Remote Sensing and
                    Geoinformation Science</a>
                </td>
              </tr>


            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Yep I know this is another <a href="https://jonbarron.info">Jon Barron</a> website.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>